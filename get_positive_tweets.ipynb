{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVFN67K7iW3m"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J36ibW4PiW3n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tweepy\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Flatten, LSTM\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter the topic you'd like to see changed Tweet sentiment on here:\n",
        "query = 'canada'"
      ],
      "metadata": {
        "id": "bVV5J86FnfiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKjk0i-IiW3p"
      },
      "source": [
        "# Import the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WWNmv_tniW3p",
        "outputId": "825ca91d-28e3-4d30-e991-13d601fdc200"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-27b712e5-7632-4d6a-a155-dc02d012fbf7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>sleep good remedi fall asleep need one</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>work fun</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>summer person love dull cold weather centralco...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>want smoke cig lighter</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>pass lot twit arriv trend topic bob</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105236</th>\n",
              "      <td>105236</td>\n",
              "      <td>i i i i i miss trip hehe turn bird amp turtl l...</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105237</th>\n",
              "      <td>105237</td>\n",
              "      <td>hump say</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105238</th>\n",
              "      <td>105238</td>\n",
              "      <td>seriou chemistri revis feel rather ill atm</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105239</th>\n",
              "      <td>105239</td>\n",
              "      <td>weekend go sound like time iphon poker girl let</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105240</th>\n",
              "      <td>105240</td>\n",
              "      <td>uff today vote eu parliament also went made cr...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>105241 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27b712e5-7632-4d6a-a155-dc02d012fbf7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-27b712e5-7632-4d6a-a155-dc02d012fbf7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-27b712e5-7632-4d6a-a155-dc02d012fbf7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Unnamed: 0  ... sentiment\n",
              "0                0  ...         0\n",
              "1                1  ...         0\n",
              "2                2  ...         1\n",
              "3                3  ...         0\n",
              "4                4  ...         0\n",
              "...            ...  ...       ...\n",
              "105236      105236  ...         1\n",
              "105237      105237  ...         0\n",
              "105238      105238  ...         0\n",
              "105239      105239  ...         0\n",
              "105240      105240  ...         1\n",
              "\n",
              "[105241 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Here we are importing our dataset of 100k tweets that we ran through our tweet cleaning script.  \n",
        "#  As we can see the script is mostly clean, but further cleaning is required\n",
        "data = pd.read_csv(\"stemmed_tweets_with_punctuation_counts.csv\", encoding='latin1', header = 0)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDxiNn8jiW3q"
      },
      "source": [
        "# Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0dr4nmssiW3q",
        "outputId": "a70eb354-b8bf-4e88-93d1-8be28ee1466a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-586fe4fe-1f30-42c7-9aa2-9861699111a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>punctuation_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sleep good remedi fall asleep need one</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>work fun</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>summer person love dull cold weather centralco...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>want smoke cig lighter</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pass lot twit arriv trend topic bob</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-586fe4fe-1f30-42c7-9aa2-9861699111a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-586fe4fe-1f30-42c7-9aa2-9861699111a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-586fe4fe-1f30-42c7-9aa2-9861699111a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               tweet  punctuation_count\n",
              "0            sleep good remedi fall asleep need one                   6\n",
              "1                                          work fun                   2\n",
              "2  summer person love dull cold weather centralco...                  3\n",
              "3                            want smoke cig lighter                   2\n",
              "4               pass lot twit arriv trend topic bob                   8"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Droping the column that was our prior index\n",
        "data.drop(data.columns[[0]], axis=1, inplace=True)\n",
        "# We decided to drop these values\n",
        "data.dropna(subset = [\"tweet\"], inplace=True)\n",
        "\n",
        "#Splitting our dataset into our label and features\n",
        "Y = data[['sentiment']]\n",
        "X = data.drop(['sentiment'], axis=1)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Bb_w7uQWiW3u",
        "outputId": "79c18f2c-e788-486a-c940-a92a686ee29c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ed88bc1b-20e8-4e9e-8d68-bc0a4642feb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ab</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abbi</th>\n",
              "      <th>abc</th>\n",
              "      <th>abil</th>\n",
              "      <th>abit</th>\n",
              "      <th>abl</th>\n",
              "      <th>abl make</th>\n",
              "      <th>abl sleep</th>\n",
              "      <th>absent</th>\n",
              "      <th>absolut</th>\n",
              "      <th>absolut love</th>\n",
              "      <th>absolut noth</th>\n",
              "      <th>abt</th>\n",
              "      <th>abus</th>\n",
              "      <th>ac</th>\n",
              "      <th>academi</th>\n",
              "      <th>accent</th>\n",
              "      <th>accept</th>\n",
              "      <th>access</th>\n",
              "      <th>accid</th>\n",
              "      <th>accident</th>\n",
              "      <th>accompani</th>\n",
              "      <th>accomplish</th>\n",
              "      <th>accord</th>\n",
              "      <th>account</th>\n",
              "      <th>ace</th>\n",
              "      <th>ach</th>\n",
              "      <th>achiev</th>\n",
              "      <th>ack</th>\n",
              "      <th>acoust</th>\n",
              "      <th>acquir</th>\n",
              "      <th>act</th>\n",
              "      <th>act like</th>\n",
              "      <th>action</th>\n",
              "      <th>activ</th>\n",
              "      <th>actor</th>\n",
              "      <th>actual</th>\n",
              "      <th>actual got</th>\n",
              "      <th>actual love</th>\n",
              "      <th>...</th>\n",
              "      <th>yike</th>\n",
              "      <th>yippe</th>\n",
              "      <th>yo</th>\n",
              "      <th>yoga</th>\n",
              "      <th>yogurt</th>\n",
              "      <th>yoo</th>\n",
              "      <th>yoou</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youngest</th>\n",
              "      <th>youth</th>\n",
              "      <th>youtub</th>\n",
              "      <th>youtub com</th>\n",
              "      <th>youtub video</th>\n",
              "      <th>youu</th>\n",
              "      <th>yr</th>\n",
              "      <th>yr ago</th>\n",
              "      <th>yr old</th>\n",
              "      <th>yu</th>\n",
              "      <th>yuck</th>\n",
              "      <th>yucki</th>\n",
              "      <th>yum</th>\n",
              "      <th>yum yum</th>\n",
              "      <th>yummi</th>\n",
              "      <th>yup</th>\n",
              "      <th>yur</th>\n",
              "      <th>yw</th>\n",
              "      <th>zac</th>\n",
              "      <th>zach</th>\n",
              "      <th>ze</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zen</th>\n",
              "      <th>zero</th>\n",
              "      <th>zip</th>\n",
              "      <th>zombi</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zoom</th>\n",
              "      <th>punctuation_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 8001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed88bc1b-20e8-4e9e-8d68-bc0a4642feb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed88bc1b-20e8-4e9e-8d68-bc0a4642feb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed88bc1b-20e8-4e9e-8d68-bc0a4642feb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    ab  abandon  abbi  abc  abil  ...  zombi  zone  zoo  zoom  punctuation_count\n",
              "0  0.0      0.0   0.0  0.0   0.0  ...    0.0   0.0  0.0   0.0           0.057692\n",
              "1  0.0      0.0   0.0  0.0   0.0  ...    0.0   0.0  0.0   0.0           0.019231\n",
              "2  0.0      0.0   0.0  0.0   0.0  ...    0.0   0.0  0.0   0.0           0.028846\n",
              "3  0.0      0.0   0.0  0.0   0.0  ...    0.0   0.0  0.0   0.0           0.019231\n",
              "4  0.0      0.0   0.0  0.0   0.0  ...    0.0   0.0  0.0   0.0           0.076923\n",
              "\n",
              "[5 rows x 8001 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Here we are holding our text and punctuation counts in their own objects for safekeeping\n",
        "tweet = X[['tweet']]\n",
        "punctuation_counts = X[['punctuation_count']]\n",
        "\n",
        "# We are using tfidf vectorizer with 8k max features in our model.  In our tfidf function we are using single words and trigrams of our text\n",
        "# Once tfidf has compiled, we are reappending our punctuation counts to the dataframe\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,3), stop_words=\"english\", max_features=8000)\n",
        "\n",
        "tfidf_vect = vectorizer.fit_transform(X['tweet'])\n",
        "tfidf_feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "tfidf_df = pd.DataFrame (tfidf_vect.todense())\n",
        "tfidf_df.columns = tfidf_feature_names\n",
        "tfidf_df['punctuation_count'] = punctuation_counts\n",
        "\n",
        "#  Here we are using min-max scaler on our punctuation counts to standardize the values\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing, model_selection\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "tfidf_df['punctuation_count'] = min_max_scaler.fit_transform(punctuation_counts)\n",
        "\n",
        "# our final dataset prior to training, the result is a very sparse matrrix of 8001 features\n",
        "tfidf_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE7YIqTqiW3v"
      },
      "outputs": [],
      "source": [
        "#test/train spllitting our data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(tfidf_df,\n",
        "                                                Y,\n",
        "                                                test_size=0.2,\n",
        "                                                random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2gyNYr3iW3v",
        "outputId": "aa629519-9e3a-4741-dc94-9097f854db07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((83793, 8001), (20949, 8001), (83793, 1), (20949, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNZKncYeiW3w"
      },
      "outputs": [],
      "source": [
        "# size/shape of dataframe\n",
        "n_samples = Xtrain.shape[0]\n",
        "n_featuers = Xtrain.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQzeCc9ViW3w"
      },
      "source": [
        "# Our Best Performing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl1AwmksiW3w"
      },
      "outputs": [],
      "source": [
        "# Make the NN -----------------------------------------------------------------\n",
        "# Importing the Keras libraries and packages\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(3000, activation='relu', name='layer1'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(200, activation='sigmoid', name='layer2'),\n",
        "        layers.Dense(40, activation='sigmoid', name='layer3'),\n",
        "        layers.Dense(1, activation='sigmoid', name='output1'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compiling the ANN\n",
        "model.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
        "\n",
        "# Here we save only our best validation accuracy as a callback.  The best accuracy is then saved as twitter_model\n",
        "model_save_filename = \"twitter_model.h5\"\n",
        "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(model_save_filename, monitor=\"val_accuracy\", save_best_only=True)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "                    Xtrain, \n",
        "                    ytrain, \n",
        "                    batch_size=10000,\n",
        "                    epochs=100, \n",
        "                    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
        "                    validation_data = (Xtest, ytest)\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mboHs5-iW3y"
      },
      "source": [
        "# Connect model to Twitter API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_GMDngliW3z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# import connection info\n",
        "twitter_api_info = pd.read_csv('connection_info.csv')\n",
        "twitter_api_info = twitter_api_info.set_index('key')\n",
        "\n",
        "API_KEY = twitter_api_info.loc['API_KEY']['value']\n",
        "API_KEY_SECRET = twitter_api_info.loc['API_KEY_SECRET']['value']\n",
        "BEARER_TOKEN = twitter_api_info.loc['BEARER_TOKEN']['value']\n",
        "ACCESS_TOKEN = twitter_api_info.loc['ACCESS_TOKEN']['value']\n",
        "ACCESS_TOKEN_SECRET = twitter_api_info.loc['ACCESS_TOKEN_SECRET']['value']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6FyITPxiW3z"
      },
      "outputs": [],
      "source": [
        "# load client\n",
        "def getClient():\n",
        "    client = tweepy.Client(bearer_token=BEARER_TOKEN,\n",
        "                           consumer_key=API_KEY,\n",
        "                           consumer_secret=API_KEY_SECRET,\n",
        "                           access_token=ACCESS_TOKEN,\n",
        "                           access_token_secret=ACCESS_TOKEN_SECRET)\n",
        "    return client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yFySeqfiW3z"
      },
      "outputs": [],
      "source": [
        "# Load tweets\n",
        "def searchTweets(client, query, max_results):\n",
        "\n",
        "    tweets = client.search_recent_tweets(query=query, max_results=max_results)\n",
        "\n",
        "    tweet_data =  tweets.data\n",
        "    results = []\n",
        "\n",
        "    if not tweet_data is None and len(tweet_data) > 0:\n",
        "        for tweet in tweet_data:\n",
        "            obj = {}\n",
        "            obj['id'] = tweet.id\n",
        "            obj['text'] = tweet.text\n",
        "            results.append(obj)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yapucbxziW3z",
        "outputId": "f97f5864-4f73-48a5-d280-36caabbd5988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['@kirstiealley Canada is such a kind country...one your hardly hear about..and now they are YELLING! I love it and support them 100%!!', \"Think people, think.\\n\\nDisagree with the convoy's message? That's ok.\\nInvoke the #EmergencyAct to shut it down? Be careful what you wish for.\\nWant a full list of donors from @GoFundMe? Ok, but be prepared to cough that up for every fundraiser in Canada. All of them.\", 'LOOK AT ALL THE GOODIES ðŸ‘€ \\n#unboxing #pov #OOTD #Canada \\nhttps://t.co/KQikBOVIGh', 'On Monday I shared a few thoughts on record high Canadian industrial property prices at the @MSCI_Inc / @realpac Canada Real Estate Investent Forum. I look at the issue here loosely through the lens of the DiPasquale-Wheaton 4-Quadrant model.  https://t.co/lvkXO1gZTj @realcapital https://t.co/vV4aWf0g4e', 'Canadaâ€™s Steele Auto expands its U.S. footprint in\\xa0Texas https://t.co/gptb3e1M2D', \"@kailahdee Do you ship internationally? I'm in Canada\", 'Do you support the convoy of truckers protesting vaccine restrictions in Canada? https://t.co/jANNtkPcbm', \"Very cold air in Canada once again spilling into the northern tier. We'll be getting colder again despite a mild start to February. Obviously, not anywhere near THIS cold.  #wtvmwx https://t.co/XpcncGey75\", '@SanaSaeed can we add soccer, too? canada is close to qualifying for the world cup!', \"@BigBEEwithItch @BCvanguards @SpencerFernando @poilievre He knows he's too incompetent to lead Canada.\"]\n"
          ]
        }
      ],
      "source": [
        "# clean tweets\n",
        "def returnTweets(query):\n",
        "    query = '{} lang:en -is:retweet'.format(query)\n",
        "\n",
        "    client = getClient()\n",
        "    tweets = searchTweets(client, query, 10)\n",
        "\n",
        "    objs = []\n",
        "\n",
        "    if len(tweets) > 0:\n",
        "        for tweet in tweets:\n",
        "            obj = {}\n",
        "            obj['text'] = tweet['text']\n",
        "            objs.append(obj)\n",
        "\n",
        "    return(objs)\n",
        "\n",
        "# Tweet topic \n",
        "tweets = returnTweets(query)\n",
        "\n",
        "# Variable for tweet list\n",
        "list_tweets = []\n",
        "for i in tweets:\n",
        "   \n",
        "    # now i is a dict, now we see the keys\n",
        "    # of the dict\n",
        "    for key in i.values():\n",
        "       \n",
        "        # print every key of each dict\n",
        "        list_tweets.append(key)\n",
        "\n",
        "\n",
        "# Look at the tweets\n",
        "print(list_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G96j3HWoiW3z"
      },
      "outputs": [],
      "source": [
        "# Preprocess tweets for prediction\n",
        "\n",
        "# Load packages\n",
        "import re\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from spellchecker import SpellChecker\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "# Remove stopwords\n",
        "stopwordlist = stopwords.words('english')\n",
        "new_stop_words=['i', 'im', 'http', 'ive', 'rt']\n",
        "for i in new_stop_words:\n",
        "    stopwordlist.append(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgU2cx1ziW3z"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function\n",
        "def preprocess(textdata):\n",
        "    processedText = []\n",
        "    punctuation_counts = []\n",
        "\n",
        "    # Create Lemmatizer and Stemmer.\n",
        "    wordstem = PorterStemmer()\n",
        "    spell = SpellChecker()\n",
        "    tk = TweetTokenizer()\n",
        "    \n",
        "    for tweet in textdata:\n",
        "        tweet = re.sub(r'@([A-Za-z0-9_]+)', '', tweet)\n",
        "        punctuation_count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
        "        punctuation_counts.append(punctuation_count(tweet,set(punctuation)))\n",
        "        tweet = tweet.lower()\n",
        "        \n",
        "        # Regex\n",
        "        tweet = re.sub('[^a-zA-Z]+', ' ', tweet)\n",
        "        sequencePattern   = r\"(.)\\1\\1+\"\n",
        "        seqReplacePattern = r\"\\1\\1\"\n",
        "        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
        "        \n",
        "        tweetwords = ''\n",
        "        for word in tk.tokenize(tweet):\n",
        "            # Checking if the word is a stopword.\n",
        "            if word not in stopwordlist:\n",
        "                # Spell check the word\n",
        "                word = spell.correction(word)\n",
        "                # Lemmatizing the word.\n",
        "                word = wordstem.stem(word)\n",
        "                tweetwords += (word+' ')\n",
        "            \n",
        "        processedText.append(tweetwords)\n",
        "        \n",
        "    return processedText, punctuation_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gWesG7tiW3z",
        "outputId": "6766c6ef-4eb2-4fbe-ae73-b4f46b07a36d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(['canada kind countri one hardli hear yell love support ', 'think peopl think disagre convoy messag ok invok emergencyact shut care wish want full list donor ok prepar cough everi fundrais canada ', 'look goodi box pov oot canada hate co kqikbovigh ', 'monday share thought record high canadian industri properti price canada real estat invest forum look issu loos len pasqual wheaton quadrant model hate co likeo get hate co ve awf i e ', 'canada steel auto expand u footprint texa hate co get e ', 'ship intern canada ', 'support convoy trucker protest vaccin restrict canada hate co janntkpcbm ', 'cold air canada spill northern tier get colder despit mild start februari obvious anywher near cold wtvmwx hate co xpcncgey ', 'add soccer canada close qualifi world cup ', 'know incompet lead canada '], [9, 13, 9, 15, 7, 2, 6, 11, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "api_tweets = preprocess(list_tweets)\n",
        "print(api_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVkKBB_UiW30"
      },
      "outputs": [],
      "source": [
        "# put tweets into a data frame\n",
        "api_df= pd.DataFrame(api_tweets[0],columns=['tweet'])\n",
        "api_df['punctuation_count'] = api_tweets[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTJ4FIv2iW30",
        "outputId": "f3a5ed47-4d56-44b3-bc96-92e8c9c0121d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10 entries, 0 to 9\n",
            "Data columns (total 2 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   tweet              10 non-null     object\n",
            " 1   punctuation_count  10 non-null     int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 288.0+ bytes\n"
          ]
        }
      ],
      "source": [
        "api_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DeKuKZNiW30"
      },
      "outputs": [],
      "source": [
        "api_tweet = api_df[['tweet']]\n",
        "api_punctuation_counts = api_df[['punctuation_count']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69V8_3pUiW30"
      },
      "outputs": [],
      "source": [
        "# Transform new data into tfidf matrix\n",
        "api_tfidf_vect = vectorizer.transform(api_df['tweet'])\n",
        "api_tfidf_feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "api_tfidf_df = pd.DataFrame (api_tfidf_vect.todense())\n",
        "api_tfidf_df.columns = api_tfidf_feature_names\n",
        "api_tfidf_df['punctuation_count'] = api_punctuation_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPBhbUr1iW30"
      },
      "outputs": [],
      "source": [
        "# scale punctuation_counts\n",
        "api_tfidf_df['punctuation_count'] = min_max_scaler.transform(api_punctuation_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCfLv6A-iW30"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model =  load_model('twitter_model.h5')\n",
        "predictions = model.predict(api_tfidf_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJHi1tlMiW31",
        "outputId": "4b09bff8-3c89-4e43-927b-3a80efc70287"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['@kirstiealley Canada is such a kind country...one your hardly hear about..and now they are YELLING! I love it and support them 100%!!',\n",
              " \"Think people, think.\\n\\nDisagree with the convoy's message? That's ok.\\nInvoke the #EmergencyAct to shut it down? Be careful what you wish for.\\nWant a full list of donors from @GoFundMe? Ok, but be prepared to cough that up for every fundraiser in Canada. All of them.\",\n",
              " 'LOOK AT ALL THE GOODIES ðŸ‘€ \\n#unboxing #pov #OOTD #Canada \\nhttps://t.co/KQikBOVIGh',\n",
              " 'On Monday I shared a few thoughts on record high Canadian industrial property prices at the @MSCI_Inc / @realpac Canada Real Estate Investent Forum. I look at the issue here loosely through the lens of the DiPasquale-Wheaton 4-Quadrant model.  https://t.co/lvkXO1gZTj @realcapital https://t.co/vV4aWf0g4e',\n",
              " 'Canadaâ€™s Steele Auto expands its U.S. footprint in\\xa0Texas https://t.co/gptb3e1M2D',\n",
              " \"@kailahdee Do you ship internationally? I'm in Canada\",\n",
              " 'Do you support the convoy of truckers protesting vaccine restrictions in Canada? https://t.co/jANNtkPcbm',\n",
              " \"Very cold air in Canada once again spilling into the northern tier. We'll be getting colder again despite a mild start to February. Obviously, not anywhere near THIS cold.  #wtvmwx https://t.co/XpcncGey75\",\n",
              " '@SanaSaeed can we add soccer, too? canada is close to qualifying for the world cup!',\n",
              " \"@BigBEEwithItch @BCvanguards @SpencerFernando @poilievre He knows he's too incompetent to lead Canada.\"]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4djA9cviW31"
      },
      "outputs": [],
      "source": [
        "# Join the predicions and tweets togeather\n",
        "change_sent_df= pd.DataFrame(predictions,columns=['predictions'])\n",
        "change_sent_df['tweets'] = list_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBTnv5KqiW31",
        "outputId": "7c2fd7c2-a380-405f-be17-14807db5d560"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predictions</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.176737</td>\n",
              "      <td>Think people, think.\\n\\nDisagree with the conv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.253721</td>\n",
              "      <td>LOOK AT ALL THE GOODIES ðŸ‘€ \\n#unboxing #pov #OO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.225488</td>\n",
              "      <td>On Monday I shared a few thoughts on record hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.166089</td>\n",
              "      <td>Canadaâ€™s Steele Auto expands its U.S. footprin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.314327</td>\n",
              "      <td>Do you support the convoy of truckers protesti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.096210</td>\n",
              "      <td>Very cold air in Canada once again spilling in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   predictions                                             tweets\n",
              "1     0.176737  Think people, think.\\n\\nDisagree with the conv...\n",
              "2     0.253721  LOOK AT ALL THE GOODIES ðŸ‘€ \\n#unboxing #pov #OO...\n",
              "3     0.225488  On Monday I shared a few thoughts on record hi...\n",
              "4     0.166089  Canadaâ€™s Steele Auto expands its U.S. footprin...\n",
              "6     0.314327  Do you support the convoy of truckers protesti...\n",
              "7     0.096210  Very cold air in Canada once again spilling in..."
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1 for Postive\n",
        "# 0 for Negative\n",
        "change_sent_df=change_sent_df[change_sent_df.predictions < 0.5]\n",
        "change_sent_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-fhKTXQiW31"
      },
      "source": [
        "# Change the sentiment of Negative tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCZ6HwHoiW31",
        "outputId": "6ffb9c5b-1d0c-49e8-c2ba-b77f24af6780"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /Users/juan-\n",
            "[nltk_data]     lukeclackworthy/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import TweetTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOjmRghGiW32"
      },
      "outputs": [],
      "source": [
        "# Get Atonyms and repace adjectives\n",
        "def get_antonyms_for_adjective(word):\n",
        "    antonyms = []\n",
        "    for word_sysnet in wn.synsets(word):\n",
        "        if word_sysnet.pos() in ['a', 's']: # Only consider adjectives\n",
        "          for lemma in word_sysnet.lemmas():\n",
        "              # a lemma is info about a word. For instance, adject bad: Synset('bad.a.01')\n",
        "              any_pos_antonyms = [ antonym.name() for antonym in lemma.antonyms() ]\n",
        "              for antonym in any_pos_antonyms:\n",
        "                  antonym_synsets = wn.synsets(antonym)\n",
        "                  if wn.ADJ not in [ ss.pos() for ss in antonym_synsets ]:\n",
        "                      continue\n",
        "                  antonyms.append(antonym)\n",
        "    return antonyms\n",
        "\n",
        "def change_sentence_sentiment(sentence):\n",
        "    tk = TweetTokenizer()\n",
        "    new_sentence = []\n",
        "\n",
        "    for word in tk.tokenize(sentence):\n",
        "        antonyms = get_antonyms_for_adjective(word)\n",
        "        \n",
        "        if len(antonyms) == 0:\n",
        "            new_sentence.append(word)\n",
        "        else:\n",
        "            new_sentence.append(antonyms[0])\n",
        "    \n",
        "    return ' '.join(new_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9X6onLxiW32",
        "outputId": "41e1d941-ed08-43a6-faee-87903e977a5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dogecoin is an nice asset , really anyone who invests in it is smart\n"
          ]
        }
      ],
      "source": [
        "sentence = \"dogecoin is an awful asset, really anyone who invests in it is stupid\"\n",
        "print(change_sentence_sentiment(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N1wX5tkiW32",
        "outputId": "94c6cc6c-6cf8-442a-cafd-c19fd8e836ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Think people, think.\\n\\nDisagree with the conv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LOOK AT ALL THE GOODIES ðŸ‘€ \\n#unboxing #pov #OO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>On Monday I shared a few thoughts on record hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Canadaâ€™s Steele Auto expands its U.S. footprin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Do you support the convoy of truckers protesti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Very cold air in Canada once again spilling in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets\n",
              "1  Think people, think.\\n\\nDisagree with the conv...\n",
              "2  LOOK AT ALL THE GOODIES ðŸ‘€ \\n#unboxing #pov #OO...\n",
              "3  On Monday I shared a few thoughts on record hi...\n",
              "4  Canadaâ€™s Steele Auto expands its U.S. footprin...\n",
              "6  Do you support the convoy of truckers protesti...\n",
              "7  Very cold air in Canada once again spilling in..."
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "changed_sent_df = change_sent_df[['tweets']]\n",
        "changed_sent_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4brDTraiW32"
      },
      "outputs": [],
      "source": [
        "changed_sent_df['Changed Sentence'] = changed_sent_df['tweets'].apply(lambda x: change_sentence_sentiment(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T2zQb_4iW33",
        "outputId": "ad300193-23b4-4d03-f5d6-32f06b4edded"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>Changed Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Think people, think.\\n\\nDisagree with the conv...</td>\n",
              "      <td>Think people , think . Disagree with the convo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LOOK AT ALL THE GOODIES ðŸ‘€ \\n#unboxing #pov #OO...</td>\n",
              "      <td>LOOK AT some THE GOODIES ðŸ‘€ #unboxing #pov #OOT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>On Monday I shared a few thoughts on record hi...</td>\n",
              "      <td>off Monday I unshared a many thoughts off reco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Canadaâ€™s Steele Auto expands its U.S. footprin...</td>\n",
              "      <td>Canada â€™ s Steele Auto expands its U . S . foo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Do you support the convoy of truckers protesti...</td>\n",
              "      <td>Do you support the convoy of truckers protesti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Very cold air in Canada once again spilling in...</td>\n",
              "      <td>Very hot air in Canada once again spilling int...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  \\\n",
              "1  Think people, think.\\n\\nDisagree with the conv...   \n",
              "2  LOOK AT ALL THE GOODIES ðŸ‘€ \\n#unboxing #pov #OO...   \n",
              "3  On Monday I shared a few thoughts on record hi...   \n",
              "4  Canadaâ€™s Steele Auto expands its U.S. footprin...   \n",
              "6  Do you support the convoy of truckers protesti...   \n",
              "7  Very cold air in Canada once again spilling in...   \n",
              "\n",
              "                                    Changed Sentence  \n",
              "1  Think people , think . Disagree with the convo...  \n",
              "2  LOOK AT some THE GOODIES ðŸ‘€ #unboxing #pov #OOT...  \n",
              "3  off Monday I unshared a many thoughts off reco...  \n",
              "4  Canada â€™ s Steele Auto expands its U . S . foo...  \n",
              "6  Do you support the convoy of truckers protesti...  \n",
              "7  Very hot air in Canada once again spilling int...  "
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "changed_sent_df"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "069624a5003d722d46b2ddcbbef8ec29c962821c31c4d6de5b70c8b5461f7514"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "get_positive_tweets.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}